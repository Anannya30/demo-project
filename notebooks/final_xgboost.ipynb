{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5a09878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1 — IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfac2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2 — LOAD DATA\n",
    "train = pd.read_csv(r\"C:\\Users\\Anannya\\demo-project\\data\\training_data.csv\")\n",
    "test  = pd.read_csv(r\"C:\\Users\\Anannya\\demo-project\\data\\test_data.csv\")\n",
    "\n",
    "# Separate features + target\n",
    "X = train.drop(\"target\", axis=1)\n",
    "y = train[\"target\"]\n",
    "\n",
    "# Make a copy for test predictions later\n",
    "test_df = test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "760729fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Columns: ['feature_1', 'feature_2', 'feature_3', 'feature_7', 'feature_9', 'feature_10', 'feature_12', 'feature_13', 'feature_17', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_29', 'feature_31', 'feature_33', 'feature_34', 'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_40', 'feature_43', 'feature_45', 'feature_47', 'feature_48', 'feature_50']\n",
      "Binary Columns: ['feature_4', 'feature_5', 'feature_6', 'feature_8', 'feature_11', 'feature_14', 'feature_15', 'feature_16', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_27', 'feature_28', 'feature_30', 'feature_32', 'feature_39', 'feature_41', 'feature_42', 'feature_44', 'feature_46', 'feature_49']\n",
      "Categorical Columns: ['id']\n"
     ]
    }
   ],
   "source": [
    "# STEP 3 — FEATURE TYPE IDENTIFICATION\n",
    "\n",
    "numeric_cols = []\n",
    "binary_cols = []\n",
    "categorical_cols = []\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        categorical_cols.append(col)\n",
    "\n",
    "    elif X[col].nunique() == 2:\n",
    "        binary_cols.append(col)\n",
    "\n",
    "    elif X[col].dtype in ['int64', 'float64']:\n",
    "        numeric_cols.append(col)\n",
    "\n",
    "print(\"Numeric Columns:\", numeric_cols)\n",
    "print(\"Binary Columns:\", binary_cols)\n",
    "print(\"Categorical Columns:\", categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e22b051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39', 'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49', 'feature_50']\n"
     ]
    }
   ],
   "source": [
    "print(X.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f044086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature count: 50\n"
     ]
    }
   ],
   "source": [
    "# STEP 4 — CLEAN DATA & DEFINE FEATURE SET\n",
    "\n",
    "# Copy dataframes to avoid modifying originals\n",
    "X = X.copy()\n",
    "test_df = test_df.copy()\n",
    "\n",
    "# If an 'id' column exists, save it for submission and drop from features\n",
    "test_ids = None\n",
    "if 'id' in X.columns:\n",
    "    X = X.drop(columns=['id'])\n",
    "if 'id' in test_df.columns:\n",
    "    test_ids = test_df['id'].copy()\n",
    "    test_df = test_df.drop(columns=['id'])\n",
    "\n",
    "# All feature columns should now be numeric or properly typed\n",
    "print(\"Final feature count:\", X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9778caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare OOF and test prediction arrays\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(test_df))\n",
    "\n",
    "# 5-fold stratified CV\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6913e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.85,\n",
    "    'colsample_bytree': 0.85,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'tree_method': 'hist',\n",
    "    'random_state': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "283b56d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5',\n",
      "       'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10',\n",
      "       'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15',\n",
      "       'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20',\n",
      "       'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25',\n",
      "       'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30',\n",
      "       'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35',\n",
      "       'feature_36', 'feature_37', 'feature_38', 'feature_39', 'feature_40',\n",
      "       'feature_41', 'feature_42', 'feature_43', 'feature_44', 'feature_45',\n",
      "       'feature_46', 'feature_47', 'feature_48', 'feature_49', 'feature_50'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e50637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1 ==========\n",
      "Fold AUC:  0.63550 | Fold Gini: 0.27099\n",
      "\n",
      "========== Fold 2 ==========\n",
      "Fold AUC:  0.63582 | Fold Gini: 0.27164\n",
      "\n",
      "========== Fold 3 ==========\n",
      "Fold AUC:  0.63732 | Fold Gini: 0.27464\n",
      "\n",
      "========== Fold 4 ==========\n",
      "Fold AUC:  0.64317 | Fold Gini: 0.28634\n",
      "\n",
      "========== Fold 5 ==========\n",
      "Fold AUC:  0.64452 | Fold Gini: 0.28904\n"
     ]
    }
   ],
   "source": [
    "for fold, (tr, val) in enumerate(kf.split(X, y)):\n",
    "    print(f\"\\n========== Fold {fold+1} ==========\")\n",
    "\n",
    "    X_tr, X_val = X.iloc[tr], X.iloc[val]\n",
    "    y_tr, y_val = y[tr], y[val]\n",
    "\n",
    "    # Train model\n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    oof_preds[val] = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Test predictions averaged\n",
    "    test_preds += model.predict_proba(test_df)[:, 1] / 5\n",
    "\n",
    "    # Fold metrics\n",
    "    fold_auc = roc_auc_score(y_val, oof_preds[val])\n",
    "    fold_gini = 2 * fold_auc - 1\n",
    "    \n",
    "\n",
    "    print(f\"Fold AUC:  {fold_auc:.5f} | Fold Gini: {fold_gini:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84dcba8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ FINAL METRICS ================\n",
      "OOF AUC:  0.639253\n",
      "OOF Gini: 0.278506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Final OOF metrics\n",
    "overall_auc = roc_auc_score(y, oof_preds)\n",
    "overall_gini = 2 * overall_auc - 1\n",
    "\n",
    "print(\"\\n================ FINAL METRICS ================\")\n",
    "print(f\"OOF AUC:  {overall_auc:.6f}\")\n",
    "print(f\"OOF Gini: {overall_gini:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a10256",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anannya\\.conda\\envs\\ds\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Assuming 'test_ids' is a list/Series of IDs corresponding to test_df\u001b[39;00m\n\u001b[32m      2\u001b[39m submission_xgb = pd.DataFrame({\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,          \u001b[38;5;66;03m# or test_ids if you have it separately\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m: test_preds          \u001b[38;5;66;03m# predicted probabilities from XGBoost\u001b[39;00m\n\u001b[32m      5\u001b[39m })\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[32m      8\u001b[39m submission_xgb.to_csv(\n\u001b[32m      9\u001b[39m     \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mAnannya\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdemo-project\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     index=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anannya\\.conda\\envs\\ds\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anannya\\.conda\\envs\\ds\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'id'"
     ]
    }
   ],
   "source": [
    "# Build submission dataframe using saved test IDs\n",
    "submission_xgb = pd.DataFrame({\n",
    "    \"id\": test_ids if test_ids is not None else pd.Series(range(len(test_preds))),\n",
    "    \"target\": test_preds\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission_xgb.to_csv(\n",
    "    r\"C:\\Users\\Anannya\\demo-project\\data\\xgboost_submission.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"XGBoost submission saved successfully!\")\n",
    "print(submission_xgb.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da720053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
